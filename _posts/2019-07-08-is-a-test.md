# 数据预处理

Created: Mar 17, 2019 10:56 AM
Property: Mar 17, 2019 10:56 AM

## 顺序：

1. 导入数据包&数据

        import pandas as pd
        import numpy as np
        
        x = df_data.iloc[:,:-1].values
        y = df_data.iloc[:,-1].values

2. 处理缺失值

        from sklearn.preprocessing import Imputer
        imputer = Imputer(missing_values='NaN', strategy='mean', axis=0)
        imputer = imputer.fit_transform(x[:,1:])

3. 离散特征归一化

        from sklearn.preprocessing import OneHotEncoder, LabelEncoder
        
        # 先用LabelEncoder标签化（因为独热只接受数值型）
        label_encoder_x = LabelEncoder()
        label_encoder_x = label_encoder_x.fit_transform(x[:,0])
        x[:,0] = label_encoder_x
        
        # 再用OneHotEncoder独热化
        onehotencoder = OneHotEncoder(categorical_features = [0])
        x = onehotencoder.fit_transform(x).toarray()

4. 拆分验证集

        from sklearn.model_selection import train_test_split
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

5. 连续特征归一化

        from sklearn.preprocessing import StandardScaler
        sc_X = StandardScaler()
        x_train = sc_X.fit_transform(x_train)
        x_test = sc_X.transform(x_test)
        
        # ps：此处的x_train进行fit后test不用再fit

# 特征归一化

## 归一化的适用：

用：基于参数的模型或者距离的模型

不用：基于树的模型，例如随机森林、Bagging、Boosting

### 离散特征归一化：

【OnehotEncoder】即独热编码，label为标签编码，目的是将数据中的离散特征进行归一化。

    from sklearn.preprocessing import OnehotEncoder
    enc = OneHotEncoder(n_values = [2, 3, 4])
    enc.fit([[0, 0, 3],
             [1, 1, 0]])
    
    ans = enc.transform([[0, 2, 3]]).toarray()
    ans
    
    >> array([[1., 0., 0., 0., 1., 0., 0., 0., 1.]])

上述n_values的目的：第二个特征fit的数据中没有2，但是transform中是有的，所以需要手动添加，添加之后导致array的长度发生了变化，本来需要2*3=6现在需要3*3=9个

categorical_features = 'all'，这个参数指定了对哪些特征进行编码，默认对所有类别都进行编码。也可以自己指定选择哪些特征
#通过索引或者 bool 值来指定，看下例：

    enc = OneHotEncoder(categorical_features = [0,2]) # 等价于 [True, False, True]
    enc.fit([[0, 0, 3],
             [1, 1, 0],
             [0, 2, 1],
             [1, 0, 2]])
    
    ans = enc.transform([[0, 2, 3]]).toarray()
    
    >> [[ 1.  0.  0.  0.  0.  1.  2.]]

sparse=True 表示编码的格式，默认为 True，即为稀疏的格式，指定 False 则就不用 toarray() 了

handle_unknown=’error’，其值可以指定为 "error" 或者 "ignore"，即如果碰到未知的类别，是返回一个错误还是忽略它。

Onehot的适用：

**用**：独热编码用来解决**类别型数据**的离散值问题

**不用**：将离散型特征进行one-hot编码的作用，是为了让**距离计算**更合理，但如果特征是离散的，并且不用one-hot编码就可以很合理的计算出距离，那么就没必要进行one-hot编码。 有些基于**树的算法**在处理变量时，并不是基于**向量空间度量**，数值只是个类别符号，即没有偏序关系，所以不用进行独热编码。 Tree Model不太需要one-hot编码： 对于决策树来说，one-hot的本质是**增加树的深度**。

对于【Label】则比较简单

    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    le.fit([1,5,67,100])
    le.transform([1,1,100,67,5])
    
    >> array([0., 0., 3., 2., 1.])

Label encoding的适用：

在某些情况下很有用，但是场景限制很多。再举一例：比如有[dog,cat,dog,mouse,cat]，我们把其转换为[1,2,1,3,2]。这里就产生了一个奇怪的现象：dog和mouse的平均值是cat。所以目前还没有发现标签编码的广泛使用。

### 分离最后一列

    train = data[:train.shape[0]]
    test = data[train.shape[0]:]